# Ollama API Settings
OLLAMA_API_URL=http://localhost:11434/api/generate

# Default model settings
DEFAULT_MODEL=llama3.1
# Available models: llama3.1, gpt-3.5-turbo, gpt-4, etc.
# Choose based on your needs and available models in Ollama

# Controls randomness in output (0.0 to 1.0)
DEFAULT_TEMPERATURE=0.85
# Adjust between 0.0 (more deterministic) and 1.0 (more random)
# Lower values for factual tasks, higher for creative tasks

# Maximum number of tokens in the generated response
DEFAULT_MAX_TOKENS=128000
# Adjust based on your needs and model capabilities
# Higher values allow longer responses but may increase processing time

# Default language for summaries
DEFAULT_SUMMARY_LANGUAGE=English
# Available options: English, Chinese, Spanish, etc.
# Choose based on your target audience

# Path to the input PDF file
INPUT_PDF_PATH=5.pdf
# Path to the output text file
OUTPUT_FILE=output.txt

# Prompt template for generating LinkedIn posts from research papers
PROMPT_TEMPLATE="As an expert in AI and computer science, your task is to read the provided paper and write a concise, fluent LinkedIn post in {language}, strictly adhering to the following framework:\n\n# Title\nCreate an attention-grabbing title summarizing the paper's main findings or conclusions. Avoid direct quotes from the paper's title, aiming for a news headline style.\n\n# Article link\n(To be filled by me)\n\n# Introduction\nIn approximately 100 words, describe the research topic, questions discussed, or field to help readers quickly grasp the article's content. Avoid repetitive phrases like 'this paper.'\n\n# First Paragraph\nIn about 100 words, provide background information on the paper, explaining the research motivation, existing challenges, or trends, and highlight the paper's innovations or breakthroughs. Use specific descriptions and vary your language.\n\n# Second Paragraph\nIn approximately 100 words, elaborate on the paper's innovations, such as new methods or frameworks, and explain their significance and contributions. Emphasize the research's novelty or distinctiveness.\n\n# Third Paragraph\nIn about 100 words, present the key findings and results, helping readers understand the core conclusions of the research. Describe the significance of the findings in simple terms.\n\n# Fourth Paragraph\nIn approximately 100 words, summarize the overall conclusions, discussing practical applications and potential future developments or challenges. Focus on practical impact and future outlook, avoiding academic jargon.\n\n## Additional Requirements\n- Maintain professionalism suitable for tech and academic fields while being accessible to general readers and AI/CS professionals.\n- Avoid overly technical or complex terminology for easy comprehension.\n- Ensure natural and fluent language, avoiding mechanical or repetitive expressions.\n- Do not use first-person pronouns.\n- Vary expressions and narrative techniques, avoiding repeated emphasis on 'this paper...'\n- Do not include subheadings except for the Article link.\n- Provide only the final content without explanations.\n- Do not use bullet points.\n- Aim for approximately 100 words per paragraph.\n- Vary the tone and style of narration throughout the post.\n- Avoid starting sentences with 'the paper' or 'the researchers' repeatedly.\n\nPaper content:\n\n{content}\n\nStrictly follow all the above format and requirements, ensuring that the generated content fully complies with the specified framework and style."

# Maximum number of retry attempts
MAX_RETRIES=3
# Delay between retry attempts in seconds
RETRY_DELAY=2

# Width of the graph in pixels
GRAPH_WIDTH=1600
# Height of the graph in pixels
GRAPH_HEIGHT=900
# Dots per inch for graph resolution
GRAPH_DPI=150
# Font for node labels
NODE_FONT=Arial
# Width of nodes in the graph
NODE_WIDTH=2
# Height of nodes in the graph
NODE_HEIGHT=0.7
# Font for edge labels
EDGE_FONT=Arial
# Maximum number of edges to display in the graph
MAX_EDGES=15

# Groq API Settings
GROQ_API_KEY=gsk_
GROQ_API_URL=https://api.groq.com/openai/v1/chat/completions
GROQ_MODEL=llama-3.1-70b-versatile
# Available models may vary, check Groq documentation for options

# Slack Bot Token for authentication
SLACK_BOT_TOKEN=xoxb-

# Slack App Token for Socket Mode
SLACK_APP_TOKEN=xxapp-

# Maximum number of concurrent PDF processing tasks
MAX_CONCURRENT_TASKS=5

# Timeout for PDF processing in seconds
PDF_PROCESSING_TIMEOUT=600

# Maximum allowed PDF file size in bytes
MAX_PDF_SIZE=10485760

# Directory to store temporary files
TEMP_DIR=/tmp/slackbot

# Log file path
LOG_FILE=/var/log/slackbot.log

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO
# Choose based on desired verbosity of logs
# DEBUG for most detailed, CRITICAL for only severe issues

# Enable or disable debug mode (True/False)
DEBUG_MODE=False
# Set to True for additional debugging information

# Allowed file extensions (comma-separated)
ALLOWED_FILE_EXTENSIONS=.pdf,.PDF

# Slack channel ID for error notifications
# ERROR_NOTIFICATION_CHANNEL=